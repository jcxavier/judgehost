<!doctype linuxdoc system>
<!--
 $Id: judge-manual.sgml 3490 2010-12-05 16:06:01Z eldering $

 DOMjudge Jury Manual
 This manual is part of the DOMjudge Programming Contest Jury System
 and licenced under the GNU GPL. See README and COPYING for details.
-->
<report>

<title>DOMjudge Jury Manual
<author>by the DOMjudge team
<date>$Date: 2010-12-05 17:06:01 +0100 (Sun, 05 Dec 2010) $

<abstract>
This document provides information about DOMjudge aimed at a jury
member operating the system during the contest: viewing and checking
submissions and working with clarification requests.

A separate manual is available for teams and administrators.

Document version: $Rev: 3490 $
</abstract>

<toc>

<chapt>DOMjudge Overview
<p>

DOMjudge is a system for running a programming contest, like the ACM
ICPC regional and world championship programming contests.

This means that teams are on-site and have a fixed time period (mostly
5 hours) and one computer to solve a number of problems (mostly 6-10).
Problems are solved by writing a program in one of the allowed
languages, that reads input according to the problem input
specification and writes the correct, corresponding output.

The judging is done by submitting the source code of the solution to
the jury. There the jury system automatically compiles and runs the
program and compares the program output with the expected output.

This software can be used to handle the submission and judging during
such contests. It also handles feedback to the teams and communication
on problems (clarification requests). It has web-interfaces for the
jury, the teams (their submissions and clarification requests) and the
public (scoreboard).

<sect>Features
<p>

A global overview of the features that DOMjudge provides:

<itemize>
<item>Automatic judging with distributed (scalable) judge hosts
<item>Web-interface for portability and simplicity
<item>Modular system for plugging in languages/compilers
<item>Detailed jury information (submissions, judgings) and options
      (rejudge, clarifications)
<item>Designed with security in mind
<item>Has been used in many live contests
<item>Open Source, Free Software
</itemize>


<sect>Copyright and licencing
<p>

DOMjudge was developed by Thijs Kinkhorst, Peter van de Werken and
Jaap Eldering at Study Association <htmlurl name="A-Eskwadraat"
url="http://www.a-eskwadraat.nl/">, <htmlurl name="Utrecht University"
url="http://www.uu.nl/">, The Netherlands.

It is Copyright (c) 2004 - 2010 by The DOMjudge Developers.

DOMjudge, including its documentation, is free software; you can redistribute
it and/or modify it under the terms of the <url name="GNU General Public License"
url="http://www.gnu.org/copyleft/gpl.html"> as published by the Free Software
Foundation; either version 2, or (at your option) any later version. See the
file COPYING.

Additionally, parts of this system are based on other programs, which
are covered by other copyrights. See the file README for details.

<sect>Contact
<p>
The DOMjudge homepage can be found at:
<htmlurl name="http://domjudge.sourceforge.net/"
url="http://domjudge.sourceforge.net/">

We have a low volume <htmlurl name="mailing list for announcements"
url="http://lists.a-eskwadraat.nl/mailman/listinfo/domjudge-announce">
of new releases.

The authors can be reached at the following address:
<htmlurl name="domjudge-devel@lists.a-eskwadraat.nl"
url="mailto:domjudge-devel@lists.a-eskwadraat.nl">

<chapt>General
<p>
The jury interface is accessed through a web browser. The main page
shows a list of various overviews, and the most important of those are
also included in the menu bar at the top. The menu bar will refresh
occasionally to allow for new information to be presented. It also has
the current `official' contest time in the top-right corner.

Most pieces of information are clickable and bring up a new page with
details. Many items also have tooltips that reveal extra information
when the mouse is hovered over them. Problem, language and team pages
have lists with corresponding submissions for that problem, language
or team. Tables can be sorted by clicking on the column headers.

The most important pages are `Submissions': the list of submitted
solutions made by teams, sorted by newest first, and `Scoreboard': the
canonical overview of current standings.

<sect>Judges and Administrators
<p>
The DOMjudge system discerns between <em>judges</em> and
<em>administrators</em> (admins). An administrator is responsible for
the technical side of DOMjudge: installation and keeping it running.
The jury web interface may be used by both.

Depending on configuration, there may either be a separate
administrator view or one is shared between judges and administrators.
In the first case you will not have access to the admin-specific
options. In the latter, you may see options directed at admins, like
options to edit or delete data. Only use these options if you're sure
that it's correct to do so.

<sect>Scoreboard
<p>
The scoreboard is the most important view on the contest.

The scoreboard will display an upcoming contest from the given
`activatetime'; the contest name and a countdown timer is shown. Only
at the first second of the real start of the contest it will show the
problems to the teams and public, however. The jury always has a full
view on the scoreboard.

It is possible to freeze the scoreboard at a given time, commonly
one hour before the contest ends, to keep the last hour interesting
for all. From that time on, the public and team scoreboard will not
be updated anymore (the jury scoreboard will) and indicate that they
are frozen. It will be unfrozen at a specified time, or by a button
click in the jury interface. Note that the way freezing works, a
submission from before the freeze and judged after may still update
the scoreboard even when frozen.

The problem headings can display the colours of balloons associated with
them, when set.

Nearly everything on the scoreboard can be clicked to reveal more
detailed information about the item in question: team names, specific
submissions and problem headers.

<chapt>Before the contest
<p>

Before the contest starts, a number of things will need to be
configured by the administrator. You can check that information,
such as the problem set(s), test data and time limits, contest
start- and end time, the time at which the scoreboard will be
frozen and unfrozen, all from the links from the front page.

Note that multiple contests can be defined, with corresponding
problem sets, for example a practice session and the real contest.

<sect>Problems and languages
<p>

The problem sets are listed under `Problems'. It is possible to change
whether teams can submit solutions for that problem (using the toggle
switch `allow submit'). If disallowed, submissions for that problem
will be rejected, but more importantly, teams will not see that
problem on the scoreboard. Disallow judge will make DOMjudge accept
submissions, but leave them queued; this is useful in case an
unexpected problem shows up with one of the problems. Timelimit is the
maximum number of seconds a submission for this problem is allowed to
run before a `TIMELIMIT' response is given (multiplied by the language
factor).

The `Languages' overview is quite the same. It has a timefactor
column; submissions in a language that has time factor 2 will be
allowed to run twice the time that has been specified under Problems.
This can be used to compensate for the execution speed of a language,
e.g. Java.

<sect>Verifying testdata
<p>

DOMjudge comes with some small tools to check for mistakes in the
testdata. These tools are all located in the <tt>misc-tools</tt>
directory in the source tree.

<descrip>
<tag>checkinput checkinput.awk fixinput.awk</tag>

The 'checkinput' programs are meant to check testdata input (and
optionally also output). They check for simple layout issues like
leading and trailing whitespace, non-printable characters, etc.
There's both a C program and AWK script which do essentially the same
thing. See 'checkinput.c' for details. All scripts take a testdata
file as argument. The 'fixinput.awk' script corrects some of these
problems.

<tag>checktestdata</tag>

This program can be used as a more advanced replacement of checkinput.
It allows you to not only check on simple (spacing) layout errors, but
a simple grammar file must be specified for the testdata, according to
which the testdata is checked. This allows e.g. for bounds checking.
See 'checktestdata.cpp' for a grammar specification. Two sample
scripts 'checktestdata.{hello,fltcmp}' are provided for the sample
problems 'hello' and 'fltcmp'.

This program can also be useful as a syntax checker for a special
compare script: it can easily handle the tedious task of verifying
that a team's submission output is syntactically valid, leaving just
the task of semantic validation to another program. When you want to
support `presentation error' as a verdict, also in variable output
problems, the option <tt>--whitespace-ok</tt> can be useful. This
allows any non-empty sequence of whitespace (no newlines though) where
the <tt>SPACE</tt> command is used, as well as leading and trailing
whitespace on lines (when using the <tt>NEWLINE</tt> command). Please
note that with this option enabled, whitespace matching is greedy, so
the script code
<code>
INT(1,2) SPACE SPACE INT(1,2)
</code>
does <em>not</em> match <tt>1__2</tt> (where the two underscores
represent spaces), because the first <tt>SPACE</tt> command already
matches both, so the second cannot match anything.
</descrip>

<sect>Testing jury solutions
<p>

Before a contest, you will want to have tested your reference
solutions on the system to see whether those are judged as expected
and maybe use their runtimes to set timelimits for the problems.
There is no special method to test such solutions; the easiest way is
to submit these as a special team before the contest. This requires
some special care and coordination with the contest administrator. See
the administrator's manual for more details.

<sect>Practice Session
<p>

If your contest has a test session or practice contest, use it also as
a general rehearsal of the jury system: judge test submissions as you
would do during the real contest and answer incoming clarification
requests.


<chapt>During the contest
<p>

<sect>Monitor teams
<p>
Under the Teams menu option, you can get a general impression of the
status of each team: a traffic light will show either of the
following:
<descrip>
<tag>gray  </tag>the team has not (yet) connected to the web interface at all;
<tag>red   </tag>the team has connected but not submitted anything yet;
<tag>yellow</tag>one or more submissions have been made, but none correct;
<tag>green </tag>the team has made at least one submission that has
                 been judged as correct.
</descrip>

This is especially useful during the practice session, where it is
expected that every team can make at least one correct submission. A
team with any other colour than green near the end of the session
might be having difficulties.


<sect>Judging Submissions
<p>

<sect1>Flow of submitted solutions 
<p>

The flow of an incoming submission is as follows.

<enum>
<item>Team submits solution. It will either be rejected after basic
      checks, or accepted and stored as a <em>submission</em>.
<item>The first available <em>judgehost</em> compiles, runs and checks
      the submission. The outcome and outputs are stored as a
      <em>judging</em> of this submission.
<item>If verification is not required, the result is automatically
      recorded and the team can view the result and the scoreboard is
      updated (unless after the scoreboard freeze). A judge can
      optionally inspect the submission and judging and mark it
      verified.
<item>If verification is required, a judge inspects the judging. Only
      after it has been approved (marked as <em>verified</em>) will
      the result be visible outside the jury interface.
</enum>

<sect1>Submission judging status codes
<p>
The interface for jury and teams shows the status of a submission with
a code.
<descrip>
<tag>QUEUED/PENDING</tag>submission received and awaiting a judgehost to process it *;
<tag>JUDGING       </tag>a judgehost is currently compiling/running/testing the submission *;
<tag>TOO-LATE      </tag>submission received but submitted after the contest ended;
<tag>CORRECT       </tag>submission correct, problem solved;
<tag>COMPILER-ERROR</tag>the compiler gave an error while compiling the program;
<tag>TIMELIMIT     </tag>program execution time exceeded the time defined for the problem;
<tag>RUN-ERROR     </tag>a kind of problem while running the program occurred, for example
                         segmentation fault, division by zero or exitcode unequal to 0;
<tag>NO-OUTPUT     </tag>there was no output at all from the program;
<tag>WRONG-ANSWER  </tag>the output of the program did not exactly match the expected output;
<tag>PRESENTATION-ERROR</tag>the submission only had presentation errors; e.g. difference
                             in whitespace with the reference output.
</descrip>
* in the team interface a submission will only show as PENDING to
prevent leaking information of problem time limits. The jury can see
whether a submission is QUEUED or JUDGING. In case of required
verification, a submission will show as PENDING to the team until the
judging has been verified.

Under the Submissions menu, you can see submitted solutions, with
the newest one at the top. Click on a submission line
for more details about the submission (team name, submittime etc),
a list of judgings and the details for the most recent judging
(runtime, outputs, diff with testdata). There is also a switch
available between newest 50, only unverified or all submissions.

Under the submission details the source filename can be clicked to
inspect the source code. If the team has submitted code in the same
language for this problem before, a diff output between the current
and previous submission is also available there.

A submission can have multiple judgings, but only one valid judging at
any time. Multiple judgings occur when rejudging, see <ref
id="rejudging" name="Rejudging">.

<sect1>Rejudging <label id="rejudging">
<p>
In some situations it is necessary to rejudge a submission. This means
that the submission will re-enter the flow as if it had not been
judged before. The submittime will be the original time, but the
program will be compiled, run and tested again.

This can be useful when there was some kind of problem: a compiler
that was broken and later fixed, or testdata that was incorrect and
later changed. When a submission is rejudged, the old judging data is
kept but marked as `invalid'.

You can rejudge a single submission by pressing the `Rejudge' button
when viewing the submission details. It is also possible to rejudge
all submissions for a given language, problem, team or judgehost; to
do so, go to the page of the respective language, problem, team or
judgehost, press the `Rejudge all' button and confirm.

Submissions that have been marked as `CORRECT' will not be rejudged.
Only DOMjudge admins can override this restriction for individual
submissions.

Teams will not get explicit notifications of rejudgings, other than a
potentially changed outcome of their submissions. It might be desirable
to combine rejudging with a clarification to the team or all teams
explaining what has been rejudged and why.

<sect1>Ignored submissions
<p>
Finally, there is the option to <em>ignore</em> specific submissions
using the button on the submission page. When a submissions is being
ignored, it is as if was never submitted: it is not visible to the
team that sent it nor on the scoreboard. It will show striked through
in the jury submissions list though. This can be used to effectively
delete a submission for some reason, e.g. when a team erroneously sent
it for the wrong problem. The submission can also be unignored again.

<sect>Clarification Requests
<p>
Communication between teams and jury happens through Clarification
Requests. Everything related to that is handled under the
Clarifications menu item.

<p>
Teams can use their web interface to send a clarification request to
the jury. The jury can send a response to that team specifically, or
send it to all teams. The latter is done to ensure that all teams have
the same information about the problem set. The jury can also send a
clarification that does not correspond to a specific request. These
will be termed `general clarifications'.

<p>
Under Clarifications, three lists are shown: new clarifications,
answered clarifications and general clarifications. It lists the team
login, the time and an excerpt. Click the excerpt for details about
that clarification request.

<p>
Every incoming clarification request will initially be marked as
unanswered. The menu bar shows the number of unanswered requests. A
request will be marked as answered when a response has been sent.
Additionally it's possible to mark a clarification request as answered
with the button that can be found when viewing the request. The latter
can be used when the request has been dealt with in some other way,
for example by sending a general message to all teams.

<p>
An answer to a clarification request is made by putting the text in the
input box under the request text. The original text is quoted. You can
choose to either send it to the team that requested the clarification,
or to all teams. In the latter case, make sure you phrase it in such a
way that the message is self-contained (e.g. by keeping the quoted
text), since the other teams cannot view the original request.

<p>
The menu on every page of the jury interface will mention the number
of unanswered clarification requests: ``(1 new)''. This number is
automatically updated, even without reloading the page.


<chapt>After the contest
<p>
Once the contest is over, the system will still accept submissions but
will not judge them anymore. Teams will see this as a `TOO-LATE'
response.

<p>
If the scoreboard was frozen, it will remain frozen until the time set
as unfreeze time, as seen under Contests. It is possible to publish
the final standings at any given moment by pressing the `unfreeze
scoreboard now' button under contests.

<p>
There's not much more to be done after the contest has ended. The
administrator will need to take care of backing up all system data and
submissions, and the awards ceremony can start.


</report>
